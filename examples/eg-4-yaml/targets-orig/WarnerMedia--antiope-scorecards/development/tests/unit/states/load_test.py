import json
import os
from io import StringIO
from unittest.mock import Mock, patch

import botocore.stub
import pytest
import yaml
from assertpy import assert_that

from lib.dynamodb import accounts_table, requirements_table, user_table, config_table
from states import load


class TestDocumentationHandler:
    def test_load_handler(self, s3_stubber):
        """Tests load handler"""
        loaded_accounts = [
            {'account_id': '111111111111', 'payer_id': '555555121212', 'cross_account_role': 'somearn'},
            {'account_id': '222222222222', 'payer_id': '555555121212'},
            {'account_id': '333333333333'}
        ]

        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps({'accounts': loaded_accounts}))},
            {'Bucket': os.environ.get('ACCOUNT_BUCKET'), 'Key': os.environ.get('ACCOUNT_FILE_PATH')}
        )

        loaded_users = [
            {'email': 'user1@example.com', 'attribute': 'value'},
            {'email': 'user2@example.com', 'otherAttribute': 'value'},
        ]
        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps(loaded_users))},
            {'Bucket': os.environ.get('USER_BUCKET'), 'Key': os.environ.get('USER_FILE_PATH')}
        )

        with open('tests/unit/states/load-test-files/requirements.yml') as file:
            raw_yaml = file.read()

        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(raw_yaml)},
            {'Bucket': os.getenv('REQUIREMENTS_BUCKET'), 'Key': os.getenv('REQUIREMENTS_FILE_PATH')}
        )

        result_from_load_handler = load.load_handler({}, {})

        expected_results = {
            'accountIds': ['111111111111', '222222222222', '333333333333'],
            'payerIds': ['555555121212'],
            's3RequirementIds': ['S3REQID01', 'S3REQID02'],
            'cloudsploitSettingsMap': {
                'settings1': {'setting_value': 100, 'other_setting': True},
                'default': {'setting_value': 1000, 'other_setting': False}
            }
        }
        result_from_load_handler['accountIds'] = sorted(result_from_load_handler['accountIds'])
        expected_results['accountIds'] = sorted(expected_results['accountIds'])

        result_from_load_handler['s3RequirementIds'] = sorted(result_from_load_handler['s3RequirementIds'])
        expected_results['s3RequirementIds'] = sorted(expected_results['s3RequirementIds'])
        assert result_from_load_handler == expected_results

    def test_load_accounts_add_delete(self, s3_stubber):
        """Tests for syncing accounts with those present in S3"""
        # create initial accounts
        initial_accounts = [
            {'account_id': '111111111111', 'payer_id': '555555121212'},
            {'account_id': '222222222222', 'payer_id': '555555121212'},
            {'account_id': '333333333333', 'payer_id': '555555121212'},
            {'account_id': '555555555555'}
        ]
        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps({'accounts': initial_accounts}))},
            {'Bucket': os.environ.get('ACCOUNT_BUCKET'), 'Key': os.environ.get('ACCOUNT_FILE_PATH')}
        )

        load.load_accounts()

        # confirm accounts we expect are in table
        for account in initial_accounts:
            accounts_table.normalize_account_record(account)
        accounts_in_db = sorted(accounts_table.scan_all(), key=lambda a: a['accountId'])
        assert accounts_in_db == initial_accounts

        # update accounts
        updated_accounts = [
            {'account_id': '111111111111', 'payer_id': '000000000000'}, # modify
            {'account_id': '222222222222', 'payer_id': '555555121212'}, # stays same
            # delete account 333333333333
            {'account_id': '444444444444', 'payer_id': '555555121212'}, # new
            {'account_id': '555555555555', 'payer_id': '555555121212'},  # modify
        ]

        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps({'accounts': updated_accounts}))},
        )
        load_accounts_response = load.load_accounts()

        for account in updated_accounts:
            accounts_table.normalize_account_record(account)

        accounts_in_db = sorted(accounts_table.scan_all(), key=lambda a: a['accountId'])
        assert accounts_in_db == updated_accounts
        assert load_accounts_response == updated_accounts

        s3_stubber.assert_no_pending_responses()

    def test_load_user_add_delete(self, s3_stubber):
        """Tests for syncing users with those present in S3"""
        # create initial users
        initial_users = [
            {'email': 'user1@example.com', 'attribute': 'value'},
            {'email': 'user2@example.com', 'otherAttribute': 'value'},
        ]
        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps(initial_users))},
            {'Bucket': os.environ.get('USER_BUCKET'), 'Key': os.environ.get('USER_FILE_PATH')}
        )

        load_user_response = load.load_user()

        # confirm users we expect to be added exist in db
        users_in_db = user_table.scan_all()
        for user in initial_users:
            assert user in users_in_db
            # remove users we know about from db results, for next check
            users_in_db.remove(user)

        assert load_user_response == initial_users

        non_admins_remaining = [user for user in users_in_db if user.get('Admin', False)]
        assert non_admins_remaining == []

        # test removing users from db
        updated_users = []
        s3_stubber.add_response('get_object', {'Body': StringIO(json.dumps(updated_users))})

        load.load_user()

        # confirm users are removed from db
        users_in_db = user_table.scan_all()
        for user in initial_users:
            assert user not in users_in_db

        s3_stubber.assert_no_pending_responses()

    def test_load_user_add_delete_camel_case(self, s3_stubber):
        """Tests for syncing users with those present in S3 in which S3 data contains camelCase emails"""
        # create initial users
        initial_users = [
            {'email': 'userOne@example.com', 'attribute': 'value'},
            {'email': 'userTwo@example.com', 'otherAttribute': 'value'},
        ]
        initial_users_downcase = [
            {'email': 'userone@example.com', 'attribute': 'value'},
            {'email': 'usertwo@example.com', 'otherAttribute': 'value'},
        ]
        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(json.dumps(initial_users))},
            {'Bucket': os.environ.get('USER_BUCKET'), 'Key': os.environ.get('USER_FILE_PATH')}
        )

        load_user_response = load.load_user()

        # confirm users we expect to be added exist in db
        users_in_db = user_table.scan_all()
        for user in initial_users_downcase:
            assert user in users_in_db
            # remove users we know about from db results, for next check
            users_in_db.remove(user)

        assert load_user_response == initial_users_downcase

        non_admins_remaining = [user for user in users_in_db if user.get('Admin', False)]
        assert non_admins_remaining == []

        # test removing users from db
        updated_users = []
        s3_stubber.add_response('get_object', {'Body': StringIO(json.dumps(updated_users))})

        load.load_user()

        # confirm users are removed from db
        users_in_db = user_table.scan_all()
        for user in initial_users:
            assert user not in users_in_db

        s3_stubber.assert_no_pending_responses()

    def test_load_user_admin_updated(self, s3_stubber):
        """Tests for syncing admin users with those present in S3"""
        # create initial admin users.
        initial_users = [
            {'email': 'user3@example.com', 'isAdmin': True, 'attribute': 'value1'},
            {'email': 'user4@example.com', 'isAdmin': True, 'attribute': 'value1'},
            {'email': 'user5@example.com', 'isAdmin': True, 'attribute': 'value1'},
        ]
        for user in initial_users:
            user_table.put_item(Item=user)

        # update admin users
        updated_users = [
            {'email': 'user3@example.com', 'attribute': 'value2'}, # update attribute
            {'email': 'user4@example.com'}, # remove attribute
            # deleting user5@example.com # should remove attributes but leave isAdmin
        ]
        s3_stubber.add_response('get_object', {'Body': StringIO(json.dumps(updated_users))})
        load.load_user()

        users_in_db = user_table.scan_all()
        assert {'email': 'user3@example.com', 'isAdmin': True, 'attribute': 'value2'} in users_in_db
        assert {'email': 'user4@example.com', 'isAdmin': True} in users_in_db
        assert {'email': 'user5@example.com', 'isAdmin': True} in users_in_db

    def test_update_requirements(self):
        """Tests for syncing requirements with those present in requirement-table"""
        # create initial requirements
        initial_requirements = {
            '111': {'requirementId': '111', 'attribute': '123'},
            '222': {'requirementId': '222', 'attribute': '123'},
            '333': {'requirementId': '333', 'attribute': '123'},
        }
        load.update_requirements(initial_requirements)

        # confirm requirements we expect are in table
        requirements_in_db = sorted(requirements_table.scan_all(), key=lambda a: a['requirementId'])
        assert list(initial_requirements.values()) == requirements_in_db

        # update requirements
        updated_requirements = {
            '111': {'requirementId': '111', 'attribute': '444'}, # modify
            '222': {'requirementId': '222', 'attribute': '123'}, # stays same
            # delete requriement '333'
            '444': {'requirementId': '444', 'attribute': '123'}, # new
        }
        load.update_requirements(updated_requirements)

        # confirm requirements we expect are in table
        requirements_in_db = sorted(requirements_table.scan_all(), key=lambda a: a['requirementId'])
        assert list(updated_requirements.values()) == requirements_in_db

    def test_update_exclusion_types(self):
        test_config = {
            'configId': config_table.EXCLUSIONS,
            'config': 'configurations2',
        }

        config_table.put_item(Item=test_config)
        load.update_exclusion_types(test_config['config'])

        config_from_dynamodb = config_table.get_config(test_config['configId'])
        assert config_from_dynamodb == 'configurations2'

    def test_update_version(self):
        test_version = {
            'configId': config_table.VERSION,
            'config': 'version50'
        }
        config_table.put_item(Item=test_version)
        load.update_version(test_version['config'])

        config_from_dynamodb = config_table.get_config(test_version['configId'])
        assert config_from_dynamodb == 'version50'

    def test_update_severity_colors(self):
        test_version = {
            'configId': config_table.SEVERITYCOLORS,
            'config': {
                'ok': {
                    'background': 'FFFFFF',
                    'text': '11111'
                }
            }
        }
        config_table.put_item(Item=test_version)
        load.update_severity_colors(test_version['config'])

        config_from_dynamodb = config_table.get_config(test_version['configId'])
        assert config_from_dynamodb == {'ok':{'background': 'FFFFFF', 'text': '11111'}}

    @patch('states.load.update_remediations', wraps=load.update_remediations)
    @patch('states.load.update_requirements', wraps=load.update_requirements)
    @patch('states.load.update_exclusion_types', wraps=load.update_exclusion_types)
    @patch('states.load.update_version', wraps=load.update_version)
    @patch('states.load.update_severity_colors', wraps=load.update_severity_colors)
    def test_load_requirements(self,
                               update_severity_colors: Mock, update_css: Mock, update_exclusion: Mock,
                               update_requirements: Mock, update_remediations: Mock, s3_stubber):
        """Tests for loading requirements with those present in S3 and
        ensuring update functions are called appropriately"""
        with open('tests/unit/states/load-test-files/requirements.yml') as file:
            raw_yaml = file.read()

        s3_stubber.add_response(
            'get_object',
            {'Body': StringIO(raw_yaml)},
            {'Bucket': os.getenv('REQUIREMENTS_BUCKET'), 'Key': os.getenv('REQUIREMENTS_FILE_PATH')}
        )
        requirements_file = yaml.safe_load(raw_yaml)

        response = load.load_requirements()

        update_exclusion.assert_called_once()
        update_requirements.assert_called_once()
        update_css.assert_called_once()
        update_severity_colors.assert_called_once()
        update_remediations.assert_called_once()

        assert response['cloudsploitSettingsMap'] == requirements_file['cloudsploitSettings']

        for requirement_id, requirement in response['requirements'].items():
            assert requirement['requirementId'] == requirement_id
            assert 'weight' in requirement
            assert_that(requirement).is_equal_to(
                requirements_file['database'][requirement_id], ignore=['requirementId', 'weight'])

        s3_stubber.assert_no_pending_responses()


@pytest.fixture(scope='function')
def s3_stubber():
    with botocore.stub.Stubber(load.client_s3) as s3_stubber:
        yield s3_stubber
